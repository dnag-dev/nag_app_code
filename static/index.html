<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Nag - The Digital Twin</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      margin: 0;
      font-family: 'Segoe UI', sans-serif;
      background: linear-gradient(to bottom right, #000000, #1a1a1a);
      color: #fff;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      overflow: hidden;
    }
    h1 { font-size: 2rem; margin-bottom: 0.2rem; }
    p { margin-top: 0; font-style: italic; opacity: 0.8; }
    #orb {
      width: 120px; height: 120px; border-radius: 50%;
      margin: 2rem auto;
      background: radial-gradient(circle, #00f2ff, #001f3f);
      box-shadow: 0 0 25px rgba(0,255,255,0.6);
      transition: all 0.4s ease-in-out;
      animation: pulseIdle 2s infinite;
    }
    #orb.listening {
      background: radial-gradient(circle, #ff7300, #a62c00);
      animation: pulseListening 1s infinite;
    }
    #orb.speaking {
      background: radial-gradient(circle, #00ff8c, #004d33);
      animation: pulseSpeaking 1s infinite;
    }
    #orb.thinking {
      background: radial-gradient(circle, #ffcc00, #cc7700);
      animation: pulseThinking 1.5s infinite;
    }
    @keyframes pulseIdle {
      0%, 100% { transform: scale(1); box-shadow: 0 0 20px rgba(0,255,255,0.2); }
      50% { transform: scale(1.05); box-shadow: 0 0 30px rgba(0,255,255,0.4); }
    }
    @keyframes pulseListening {
      0%, 100% { transform: scale(1); box-shadow: 0 0 30px rgba(255,115,0,0.3); }
      50% { transform: scale(1.1); box-shadow: 0 0 40px rgba(255,115,0,0.5); }
    }
    @keyframes pulseSpeaking {
      0%, 100% { transform: scale(1); box-shadow: 0 0 30px rgba(0,255,140,0.4); }
      50% { transform: scale(1.1); box-shadow: 0 0 40px rgba(0,255,140,0.6); }
    }
    @keyframes pulseThinking {
      0%, 100% { transform: scale(1); box-shadow: 0 0 30px rgba(255,204,0,0.3); }
      50% { transform: scale(1.08); box-shadow: 0 0 40px rgba(255,204,0,0.5); }
    }
    #debug {
      width: 90%;
      max-height: 250px;
      overflow-y: auto;
      background: #111;
      border: 1px solid #333;
      padding: 10px;
      font-family: monospace;
      font-size: 0.85rem;
      color: #0f0;
      margin-top: 2rem;
    }
    #toggleButton {
      padding: 10px 20px;
      font-size: 1rem;
      margin-top: 1rem;
      border: none;
      background-color: #00f2ff;
      color: #000;
      border-radius: 10px;
      cursor: pointer;
    }
    #toggleButton:disabled {
      background-color: #555;
      cursor: not-allowed;
    }
  </style>
</head>
<body>
  <h1>Welcome to Nag</h1>
  <p>The digital extension of Dinakara's mind ‚Äî therapist, companion, unfiltered mirror.</p>
  <div id="orb" class="idle"></div>
  <audio id="audio" hidden></audio>
  <button id="toggleButton">Start Conversation</button>
  <div id="debug"><strong>Debug Log:</strong></div>

  <script>
    const orb = document.getElementById("orb");
    const audio = document.getElementById("audio");
    const debugBox = document.getElementById("debug");
    const toggleButton = document.getElementById("toggleButton");

    let mediaRecorder;
    let audioChunks = [];
    let stream;
    let listening = false;
    let interrupted = false;

    // Check if MediaRecorder is supported
    if (!window.MediaRecorder) {
      logDebug("‚ö†Ô∏è Your browser doesn't support MediaRecorder API!");
      toggleButton.disabled = true;
      toggleButton.textContent = "Not supported in this browser";
    }

    function logDebug(msg) {
      const p = document.createElement("p");
      p.textContent = msg;
      debugBox.appendChild(p);
      debugBox.scrollTop = debugBox.scrollHeight;
    }

    async function startListening() {
      try {
        orb.classList.remove("idle", "speaking", "thinking");
        orb.classList.add("listening");
        logDebug("üéôÔ∏è Listening...");

        stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // Try different MIME types in order of preference
        let mimeType = "";
        const supportedTypes = [
          "audio/webm",
          "audio/mp4",
          "audio/mpeg",
          "audio/ogg;codecs=opus",
          ""  // Empty string as last resort (browser default)
        ];
        
        for (const type of supportedTypes) {
          if (MediaRecorder.isTypeSupported(type)) {
            mimeType = type;
            logDebug(`Using audio format: ${mimeType || "browser default"}`);
            break;
          }
        }
        
        // Create MediaRecorder with the supported type (or browser default if none found)
        mediaRecorder = new MediaRecorder(stream, mimeType ? { mimeType } : {});
        audioChunks = [];

        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);

        mediaRecorder.onstop = async () => {
          if (interrupted) return;
          orb.classList.remove("listening");
          
          // Use the same MIME type for the blob
          const blob = new Blob(audioChunks, mimeType ? { type: mimeType } : {});
          const formData = new FormData();
          
          // Determine appropriate file extension based on MIME type
          let fileExt = "audio";
          if (mimeType.includes("webm")) fileExt = "webm";
          else if (mimeType.includes("mp4") || mimeType.includes("mpeg")) fileExt = "mp3";
          else if (mimeType.includes("ogg")) fileExt = "ogg";
          
          formData.append("file", blob, `input.${fileExt}`);

          try {
            logDebug("üì§ Uploading voice...");
            const res = await fetch("/transcribe", { 
              method: "POST", 
              body: formData 
            });

            let data;
            try {
              data = await res.json();
            } catch (jsonErr) {
              logDebug("‚ùå JSON parse failed: " + jsonErr.message);
              orb.classList.add("idle");
              return;
            }

            const message = (data.transcription || "").trim();
            logDebug("üìù Transcribed: " + message);

            if (!message || message === "undefined") {
              logDebug("‚ö†Ô∏è Empty message. Skipping...");
              orb.classList.add("idle");
              return;
            }

            await sendToChat(message);
          } catch (e) {
            logDebug("‚ùå Transcription error: " + e.message);
            orb.classList.add("idle");
          }
        };

        mediaRecorder.start();
        setTimeout(() => {
          if (mediaRecorder && mediaRecorder.state !== "inactive") {
            mediaRecorder.stop();
          }
        }, 4000);
      } catch (e) {
        logDebug("üö´ Mic access failed: " + e.message);
        orb.classList.remove("listening");
        orb.classList.add("idle");
      }
    }

    async function stopListening() {
      interrupted = true;
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      if (!audio.paused) {
        audio.pause();
        audio.currentTime = 0;
      }
    }

    async function sendToChat(message) {
      orb.classList.remove("listening", "idle", "speaking");
      orb.classList.add("thinking");
      logDebug("üí¨ Sending to Nag...");

      try {
        const res = await fetch("/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message })
        });

        let data;
        try {
          data = await res.json();
        } catch (jsonErr) {
          logDebug("‚ùå Chat response JSON parse failed: " + jsonErr.message);
          orb.classList.remove("thinking");
          orb.classList.add("idle");
          return;
        }

        logDebug("üß† Nag: " + data.response);
        orb.classList.remove("thinking");

        if (data.audio_url) {
          orb.classList.add("speaking");
          audio.src = data.audio_url;
          audio.load();
          
          try {
            await audio.play();
          } catch (e) {
            logDebug("üîá Audio play failed: " + e.message);
            orb.classList.remove("speaking");
            orb.classList.add("idle");
            return;
          }

          audio.onended = () => {
            orb.classList.remove("speaking");
            orb.classList.add("idle");
            if (!interrupted) startListening();
          };
        } else {
          logDebug("‚ö†Ô∏è No audio returned.");
          orb.classList.add("idle");
        }
      } catch (e) {
        logDebug("‚ùå Chat error: " + e.message);
        orb.classList.remove("thinking");
        orb.classList.add("idle");
      }
    }

    toggleButton.addEventListener("click", async () => {
      if (listening) {
        logDebug("‚èπÔ∏è Stopping conversation...");
        toggleButton.textContent = "Resume Conversation";
        await stopListening();
        orb.classList.remove("listening", "speaking", "thinking");
        orb.classList.add("idle");
      } else {
        logDebug("‚ñ∂Ô∏è Starting conversation...");
        toggleButton.textContent = "Stop Conversation";
        interrupted = false;
        await startListening();
      }
      listening = !listening;
    });

    // Log initial browser capabilities
    if (window.MediaRecorder) {
      logDebug("‚úÖ MediaRecorder is supported in this browser");
      const supportedTypes = [
        "audio/webm", 
        "audio/mp4", 
        "audio/mpeg", 
        "audio/ogg;codecs=opus"
      ];
      for (const type of supportedTypes) {
        logDebug(`${type}: ${MediaRecorder.isTypeSupported(type) ? '‚úÖ' : '‚ùå'}`);
      }
    }
  </script>
</body>
</html>